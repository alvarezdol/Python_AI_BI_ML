{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'doggy-boot-harness.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\GoHere\\T_Labs\\Projects\\Python_Tests\\Jupyter_Books\\Jupyter_test.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GoHere/T_Labs/Projects/Python_Tests/Jupyter_Books/Jupyter_test.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mwget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-boot-harness.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GoHere/T_Labs/Projects/Python_Tests/Jupyter_Books/Jupyter_test.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Read the text file containing data using pandas\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/GoHere/T_Labs/Projects/Python_Tests/Jupyter_Books/Jupyter_test.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m dataset \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mdoggy-boot-harness.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GoHere/T_Labs/Projects/Python_Tests/Jupyter_Books/Jupyter_test.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Print the data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GoHere/T_Labs/Projects/Python_Tests/Jupyter_Books/Jupyter_test.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Because there are a lot of data, use head() to only print the first few rows\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GoHere/T_Labs/Projects/Python_Tests/Jupyter_Books/Jupyter_test.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m dataset\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\mrtim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mrtim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\mrtim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\mrtim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\mrtim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m     f,\n\u001b[0;32m   1220\u001b[0m     mode,\n\u001b[0;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1227\u001b[0m )\n\u001b[0;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\mrtim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    787\u001b[0m             handle,\n\u001b[0;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'doggy-boot-harness.csv'"
     ]
    }
   ],
   "source": [
    "# # Exercise: Datasets in Python\n",
    "# \n",
    "# In the previous exercise, we loaded some data and fit a model to it. Several aspects of this were simplified, particularly that the data was hard-coded into our python script, and we didn't spend any time really looking at the data itself.\n",
    "# \n",
    "# Here, we'll load data from a file, filter it, and graph it. Doing so is a very important first step in order to build proper models, or to understand their limitations.\n",
    "# \n",
    "# As before, there's no need to edit any code in the examples in this unit. Try to read it, understand it, then press the **Run** button to run it. As always, it's vitally important that these code blocks are run in the correct order, and nothing is missed.\n",
    "# \n",
    "# ## Load data with Pandas\n",
    "# \n",
    "# There are large variety of libraries that help you work with data. In Python, one of the most common is _Pandas_. We used pandas briefly in the previous exercise. Pandas can open data saved as text files and store it in an organized table called a `DataFrame`.\n",
    "# \n",
    "# Let's open some text data that's stored on disk. Our data is saved in a file called `doggy-boot-harness.csv`.\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "import pandas\n",
    "#get_ipython().system('wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py')\n",
    "#get_ipython().system('wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-boot-harness.csv')\n",
    "\n",
    "# Read the text file containing data using pandas\n",
    "dataset = pandas.read_csv('doggy-boot-harness.csv')\n",
    "\n",
    "# Print the data\n",
    "# Because there are a lot of data, use head() to only print the first few rows\n",
    "dataset.head()\n",
    "\n",
    "\n",
    "# As you can see, this dataset contains information about dogs, including their doggy boot size, harness size, sex, and age in years.\n",
    "# \n",
    "# Data is stored as columns and rows, similar to a table you might see in Excel.\n",
    "# \n",
    "# ## Filter data by Columns\n",
    "# \n",
    "# Data is easy to filter by columns. We can either type this directly, like `dataset.my_column_name`, or like so: `dataset[\"my_column_name\"]`.\n",
    "# \n",
    "# We can use this to either extract data, or to delete data.\n",
    "# \n",
    "# Lets take a look at the harness sizes, and delete the `sex` and `age_years` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the harness sizes\n",
    "print(\"Harness sizes\")\n",
    "print(dataset.harness_size)\n",
    "\n",
    "# Remove the sex and age-in-years columns.\n",
    "del dataset[\"sex\"]\n",
    "del dataset[\"age_years\"]\n",
    "\n",
    "# Print the column names\n",
    "print(\"\\nAvailable columns after deleting sex and age information:\")\n",
    "print(dataset.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data by Rows\n",
    "# We can get data from the top of the table by using the `head()` function, or from the bottom of the table by using the `tail()` function. \n",
    "# Both functions make a shallow copy of a section of our dataframe. Here, we're sending these copies to the `print()` function. The head and tail views can also be used for other purposes, such as for use in analyses or graphs.\n",
    "\n",
    "# Print the data at the top of the table\n",
    "print(\"TOP OF TABLE\")\n",
    "print(dataset.head())\n",
    "\n",
    "# print the data at the bottom of the table\n",
    "print(\"\\nBOTTOM OF TABLE\")\n",
    "print(dataset.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also filter logically. For example, we can look at data for dogs who have a harness smaller than a size 55.\n",
    "# \n",
    "# This works by calculating a `True` or `False` value for each row, then keeping only those rows where the value is `True`.\n",
    "\n",
    "# Print how many rows of data we have\n",
    "print(f\"We have {len(dataset)} rows of data\")\n",
    "\n",
    "# Determine whether each avalanche dog's harness size is < 55\n",
    "# This creates a True or False value for each row where True means \n",
    "# they are smaller than 55\n",
    "is_small = dataset.harness_size < 55\n",
    "print(\"\\nWhether the dog's harness was smaller than size 55:\")\n",
    "print(is_small)\n",
    "\n",
    "# Now apply this 'mask' to our data to keep the smaller dogs\n",
    "data_from_small_dogs = dataset[is_small]\n",
    "print(\"\\nData for dogs with harness smaller than size 55:\")\n",
    "print(data_from_small_dogs)\n",
    "\n",
    "# Print the number of small dogs\n",
    "print(f\"\\nNumber of dogs with harness size less than 55: {len(data_from_small_dogs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This looks like a lot of code, but we can compress the important parts into a single line.\n",
    "# \n",
    "# Let's do something similar: restrict our data to only those with boot sizes smaller than 40. \n",
    "# Make a copy of the dataset that only contains dogs with \n",
    "# a boot size below size 40\n",
    "# The call to copy() is optional but can help avoid unexpected\n",
    "# behaviour in more complex scenarios\n",
    "data_smaller_paws = dataset[dataset.boot_size < 40].copy()\n",
    "\n",
    "# Print information about this\n",
    "print(f\"We now have {len(data_smaller_paws)} rows in our dataset. The last few rows are:\")\n",
    "data_smaller_paws.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Graph Data\n",
    "# \n",
    "# Graphing data is often the easiest way to understand it. \n",
    "# \n",
    "# In these exercises, we usually make our graphs using code in a custom file we've created, called `graphing.py`, which you can look at on our github page.\n",
    "# \n",
    "# Here, we'll practice making a graph without this custom code, however.\n",
    "# \n",
    "# Lets make a simple graph of harness size versus boot size for our avalanche dogs with smaller feet. \n",
    "\n",
    "# Load and prepare plotly to create our graphs\n",
    "import plotly.express\n",
    "import graphing # this is a custom file you can find in our code on github\n",
    "\n",
    "# Show a graph of harness size by boot size:\n",
    "plotly.express.scatter(data_smaller_paws, x=\"harness_size\", y=\"boot_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Create New Columns\n",
    "# \n",
    "# The preceding graph shows the relationship we want to investigate for our store, but some customers might want harness-size lists in inches, not centimeters. How can we view these harness sizes in imperial units?\n",
    "# \n",
    "# To do this, we will need to create a new column called `harness_size_imperial` and put that on the X axis instead.\n",
    "# \n",
    "# Creating new columns uses very similar syntax to what we've seen before.\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Convert harness sizes from metric to imperial units \n",
    "# and save the result to a new column\n",
    "data_smaller_paws['harness_size_imperial'] = data_smaller_paws.harness_size / 2.54\n",
    "\n",
    "# Show a graph of harness size in imperial units\n",
    "plotly.express.scatter(data_smaller_paws, x=\"harness_size_imperial\", y=\"boot_size\")\n",
    "\n",
    "\n",
    "# We've now graphed our new column of data (`harness_size_imperial`) against boot size for dogs with small paws.\n",
    "# \n",
    "# ## Summary\n",
    "# \n",
    "# We've introduced working with data in Python, including:\n",
    "# \n",
    "# * Opening data from a file into a `DataFrame` (table)\n",
    "# * Inspecting the top and bottom of the dataframe\n",
    "# * Adding and removing columns of data\n",
    "# * Removing rows of data based on criteria\n",
    "# * Graphing data to understand trends\n",
    "# \n",
    "# Learning to work with dataframes can feel tedious or dry, but keep going, because these basic skills are critical to unlocking exciting machine-learning techniques that we'll cover in later modules.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd3b349d516eaf5c243f4256f5870d4a7387b1f85bb459b9d1ad2de002537956"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
